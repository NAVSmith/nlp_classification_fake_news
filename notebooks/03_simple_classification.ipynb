{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Fake News Classification\n",
    "\n",
    "This notebook combines data preprocessing and model training in a streamlined workflow.\n",
    "\n",
    "## Overview\n",
    "- **Goal**: Build a classifier to distinguish between real (1) and fake (0) news\n",
    "- **Approach**: Extract features, apply standard NLP preprocessing, and train a Random Forest classifier\n",
    "- **Model**: Random Forest with TF-IDF features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    print(\"Libraries imported successfully!\")\n",
    "except:\n",
    "    print(\"NLTK data download failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (39942, 5)\n",
      "Columns: ['label', 'title', 'text', 'subject', 'date']\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "0    19943\n",
      "1    19999\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/data.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing\n",
    "\n",
    "Apply preprocessing to remove news sources and caps+colon patterns, then standard NLP preprocessing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Standard Text Preprocessing\n",
    "\n",
    "Apply preprocessing to remove news sources and caps+colon patterns, then standard NLP preprocessing: lowercase conversion, URL/email removal, tokenization, stopword removal, and stemming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def standard_preprocess(text):\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    text_str = str(text)\n",
    "    \n",
    "    text_str = re.sub(r'\\(reuters\\)|\\(reuter\\)|\\(ap\\)|\\(afp\\)', '', text_str, flags=re.IGNORECASE)\n",
    "    \n",
    "    text_str = re.sub(r'\\breuters\\b', '', text_str, flags=re.IGNORECASE)\n",
    "    text_str = re.sub(r'\\breuter\\b', '', text_str, flags=re.IGNORECASE)\n",
    "    \n",
    "    text_str = re.sub(r'^[A-Z]{5,}:\\s*', '', text_str)\n",
    "    \n",
    "    text_str = text_str.lower()\n",
    "    text_str = re.sub(r'http\\S+|www\\S+|https\\S+', '', text_str)\n",
    "    text_str = re.sub(r'\\S+@\\S+', '', text_str)\n",
    "    text_str = re.sub(r'\\s+', ' ', text_str)\n",
    "    \n",
    "    try:\n",
    "        tokens = word_tokenize(text_str)\n",
    "    except:\n",
    "        tokens = text_str.split()\n",
    "    \n",
    "    tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    tokens = [token for token in tokens if len(token) > 2]\n",
    "    \n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply preprocessing to title and text columns, then combine them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 39935 articles\n"
     ]
    }
   ],
   "source": [
    "df['title_processed'] = df['title'].apply(standard_preprocess)\n",
    "df['text_processed'] = df['text'].apply(standard_preprocess)\n",
    "df['combined_text'] = df['title_processed'] + ' ' + df['text_processed']\n",
    "\n",
    "empty_text = df['combined_text'].str.strip() == ''\n",
    "df = df[~empty_text].reset_index(drop=True)\n",
    "print(f\"Processed {len(df)} articles\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preparation\n",
    "\n",
    "Drop subject and date columns, handle missing values, and create train/test split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping subject and date: ['label', 'title', 'text', 'title_processed', 'text_processed', 'combined_text']\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['subject', 'date'])\n",
    "print(f\"Columns after dropping subject and date: {df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "Series([], dtype: int64)\n",
      "Dataset shape after handling missing values: (39935, 6)\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "df = df.fillna('')\n",
    "print(f\"Dataset shape after handling missing values: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if \"reuter\" or \"reuters\" is still present in the processed text (validation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles with 'reuter' in processed text: 15\n",
      "Articles with 'reuters' in processed text: 0\n",
      "\n",
      "‚ö†Ô∏è  Warning: Some processed texts still contain 'reuter' or 'reuters'\n",
      "Sample articles with 'reuter' or 'reuters' in processed text:\n",
      "\n",
      "  Article 5119:\n",
      "    Original text (first 150 chars):  BERKELEY, Calif./LANSING, Mich. (Reuters) - Supporters of Donald Trump clashed with counter-protesters at a rally in the famously left-leaning city o...\n",
      "    Processed text (first 150 chars): day pro-trump ralli california march turn violent berkeley calif./lans mich. support donald trump clash counter-protest ralli famous left-lean citi be...\n",
      "\n",
      "  Article 5621:\n",
      "    Original text (first 150 chars):  WASHINGTON (Reuters) - The U.S. House of Representatives voted on Monday to require law enforcement authorities to obtain a search warrant before see...\n",
      "    Processed text (first 150 chars): u.s. hous pass bill requir warrant search old email washington u.s. hous repres vote monday requir law enforc author obtain search warrant seek old em...\n",
      "\n",
      "  Article 12012:\n",
      "    Original text (first 150 chars): BEKAA, Lebanon (Reuters) - In a tent in Lebanon surrounded by snow, Syrian refugees Ammar and Khadija were married by a tribal leader from their homel...\n",
      "    Processed text (first 150 chars): syrian coupl say lebanon say 'no quit bekaa lebanon tent lebanon surround snow syrian refuge ammar khadija marri tribal leader homeland wed would soon...\n"
     ]
    }
   ],
   "source": [
    "reuter_in_processed = df['combined_text'].str.contains(r'\\breuter', case=False, regex=True, na=False)\n",
    "reuters_in_processed = df['combined_text'].str.contains(r'\\breuters\\b', case=False, regex=True, na=False)\n",
    "\n",
    "print(f\"Articles with 'reuter' in processed text: {reuter_in_processed.sum()}\")\n",
    "print(f\"Articles with 'reuters' in processed text: {reuters_in_processed.sum()}\")\n",
    "\n",
    "if reuter_in_processed.sum() > 0 or reuters_in_processed.sum() > 0:\n",
    "    print(\"\\n‚ö†Ô∏è  Warning: Some processed texts still contain 'reuter' or 'reuters'\")\n",
    "    print(\"Sample articles with 'reuter' or 'reuters' in processed text:\")\n",
    "    mask = reuter_in_processed | reuters_in_processed\n",
    "    for idx in df[mask].index[:3]:\n",
    "        print(f\"\\n  Article {idx}:\")\n",
    "        print(f\"    Original text (first 150 chars): {df.loc[idx, 'text'][:150]}...\")\n",
    "        print(f\"    Processed text (first 150 chars): {df.loc[idx, 'combined_text'][:150]}...\")\n",
    "else:\n",
    "    print(\"\\n‚úì No 'reuter' or 'reuters' found in processed text - preprocessing working correctly!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create stratified train/test split (80/20).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 31948 samples\n",
      "Test set: 7987 samples\n",
      "\n",
      "Training label distribution:\n",
      "label\n",
      "0    15949\n",
      "1    15999\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test label distribution:\n",
      "label\n",
      "0    3987\n",
      "1    4000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df['combined_text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"\\nTraining label distribution:\")\n",
    "print(y_train.value_counts().sort_index())\n",
    "print(f\"\\nTest label distribution:\")\n",
    "print(y_test.value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "Train a Logistic Regression classifier with TF-IDF features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF features: 1000\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"TF-IDF features: {X_train_tfidf.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model trained successfully\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    C=0.01\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "print(\"Logistic Regression model trained successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "\n",
    "Evaluate the model performance on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Metrics:\n",
      "Accuracy:  0.9356\n",
      "Precision: 0.9251\n",
      "Recall:    0.9483\n",
      "F1-Score:  0.9365\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='binary')\n",
    "recall = recall_score(y_test, y_pred, average='binary')\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "print(\"Model Performance Metrics:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Feature Importance Analysis\n",
    "\n",
    "Analyze which words/features the model relies on most for predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Most Important Features (for predicting Real News - positive coefficients):\n",
      "======================================================================\n",
      "said                           Coefficient:   2.8243\n",
      "video                          Coefficient:  -1.9056\n",
      "th                             Coefficient:  -1.2681\n",
      "imag                           Coefficient:  -1.2022\n",
      "hillari                        Coefficient:  -1.0605\n",
      "trump                          Coefficient:  -1.0109\n",
      "washington                     Coefficient:   0.9245\n",
      "minist                         Coefficient:   0.8664\n",
      "obama                          Coefficient:  -0.8301\n",
      "watch                          Coefficient:  -0.7905\n",
      "featur                         Coefficient:  -0.7869\n",
      "know                           Coefficient:  -0.7858\n",
      "like                           Coefficient:  -0.7834\n",
      "senat                          Coefficient:   0.7425\n",
      "govern                         Coefficient:   0.7373\n",
      "wednesday                      Coefficient:   0.7269\n",
      "america                        Coefficient:  -0.7250\n",
      "com                            Coefficient:  -0.7217\n",
      "gop                            Coefficient:  -0.6946\n",
      "pic                            Coefficient:  -0.6911\n",
      "\n",
      "======================================================================\n",
      "Top 20 Features that indicate Fake News (negative coefficients):\n",
      "======================================================================\n",
      "fellow                         Coefficient:  -0.0023\n",
      "activist                       Coefficient:  -0.0022\n",
      "second                         Coefficient:  -0.0021\n",
      "accept                         Coefficient:  -0.0016\n",
      "self                           Coefficient:  -0.0013\n",
      "train                          Coefficient:  -0.0013\n",
      "past                           Coefficient:  -0.0012\n",
      "juli                           Coefficient:  -0.0011\n",
      "medic                          Coefficient:  -0.0008\n",
      "attend                         Coefficient:  -0.0006\n",
      "abus                           Coefficient:  -0.0005\n",
      "short                          Coefficient:   0.0001\n",
      "credit                         Coefficient:   0.0004\n",
      "white                          Coefficient:   0.0008\n",
      "quickli                        Coefficient:   0.0009\n",
      "latest                         Coefficient:   0.0014\n",
      "base                           Coefficient:   0.0019\n",
      "grant                          Coefficient:   0.0023\n",
      "hear                           Coefficient:   0.0024\n",
      "attack                         Coefficient:   0.0024\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf.get_feature_names_out()\n",
    "coefficients = lr_model.coef_[0]\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients,\n",
    "    'abs_coefficient': np.abs(coefficients)\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(\"Top 20 Most Important Features (for predicting Real News - positive coefficients):\")\n",
    "print(\"=\" * 70)\n",
    "top_real = feature_importance.head(20)\n",
    "for idx, row in top_real.iterrows():\n",
    "    print(f\"{row['feature']:<30} Coefficient: {row['coefficient']:>8.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Top 20 Features that indicate Fake News (negative coefficients):\")\n",
    "print(\"=\" * 70)\n",
    "top_fake = feature_importance.tail(20).sort_values('coefficient')\n",
    "for idx, row in top_fake.iterrows():\n",
    "    print(f\"{row['feature']:<30} Coefficient: {row['coefficient']:>8.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Misclassification Analysis\n",
    "\n",
    "Examine articles that were incorrectly classified to understand model failures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification Analysis:\n",
      "==================================================\n",
      "False Positives (Fake predicted as Real): 307\n",
      "False Negatives (Real predicted as Fake): 207\n",
      "Total Misclassifications: 514\n",
      "\n",
      "Sample False Positives (Fake news predicted as Real):\n",
      "\n",
      "  Article 36034:\n",
      "    Title: TRUMP ADVISOR Has Warning For Syria That Has Saved Lives [Video]...\n",
      "    Text (first 200 chars): Deputy Assistant to the President Sebastian Gorka warned Syrian President Bashar Assad after evidence arose earlier this week that the Assad regime could be planning another chemical weapons attack on...\n",
      "\n",
      "  Article 35351:\n",
      "    Title: CHICAGO THUG PRESIDENT PERSONALLY LEAKED CHUCK SCHUMER‚ÄôS OPPOSITION TO HIS DANGEROUS IRAN DEAL...\n",
      "    Text (first 200 chars): Schumer asked the President not to mention his decision publicly until he could make a formal announcement on Friday.If that s how Obama treats his closest friends who refuse to align with his reckles...\n",
      "\n",
      "  Article 37250:\n",
      "    Title: THE TOTAL COST TO TAXPAYERS FOR MOOCH‚ÄôS EUROPEAN VACATION IS SICKENING...\n",
      "    Text (first 200 chars): And they re heading to Cape Cod next! Where does it end with these people? The optics of this are just awful! We have HUGE national debt and so many Americans are suffering yet Mooch takes a glam Euro...\n",
      "\n",
      "Sample False Negatives (Real news predicted as Fake):\n",
      "\n",
      "  Article 6501:\n",
      "    Title: Comey defends actions during 'challenging' U.S. election year...\n",
      "    Text (first 200 chars): WASHINGTON (Reuters) - FBI Director James Comey on Thursday defended his handling of Democratic presidential candidate Hillary Clinton‚Äôs email investigation during the contentious U.S. presidential el...\n",
      "\n",
      "  Article 7712:\n",
      "    Title: Clinton slams Trump for comments on offensive against Islamic State...\n",
      "    Text (first 200 chars): MANCHESTER, N.H./ST. AUGUSTINE, Fla. (Reuters) - U.S. Democratic presidential candidate Hillary Clinton slammed rival Donald Trump on Monday for saying that the week-old effort to retake the Iraqi cit...\n",
      "\n",
      "  Article 3490:\n",
      "    Title: Kathy Griffin loses CNN deal after photos with fake severed Trump head...\n",
      "    Text (first 200 chars): LOS ANGELES (Reuters) - CNN fired comedian Kathy Griffin from its annual New Year‚Äôs Eve broadcast on Wednesday after she drew strong criticism for posing in photographs holding up the likeness of a bl...\n"
     ]
    }
   ],
   "source": [
    "false_positives = (y_test == 0) & (y_pred == 1)\n",
    "false_negatives = (y_test == 1) & (y_pred == 0)\n",
    "\n",
    "fp_count = false_positives.sum()\n",
    "fn_count = false_negatives.sum()\n",
    "\n",
    "print(\"Misclassification Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"False Positives (Fake predicted as Real): {fp_count}\")\n",
    "print(f\"False Negatives (Real predicted as Fake): {fn_count}\")\n",
    "print(f\"Total Misclassifications: {fp_count + fn_count}\")\n",
    "\n",
    "if fp_count > 0:\n",
    "    print(f\"\\nSample False Positives (Fake news predicted as Real):\")\n",
    "    fp_indices = X_test[false_positives].index[:3]\n",
    "    for idx in fp_indices:\n",
    "        print(f\"\\n  Article {idx}:\")\n",
    "        print(f\"    Title: {df.loc[idx, 'title'][:100]}...\")\n",
    "        print(f\"    Text (first 200 chars): {df.loc[idx, 'text'][:200]}...\")\n",
    "\n",
    "if fn_count > 0:\n",
    "    print(f\"\\nSample False Negatives (Real news predicted as Fake):\")\n",
    "    fn_indices = X_test[false_negatives].index[:3]\n",
    "    for idx in fn_indices:\n",
    "        print(f\"\\n  Article {idx}:\")\n",
    "        print(f\"    Title: {df.loc[idx, 'title'][:100]}...\")\n",
    "        print(f\"    Text (first 200 chars): {df.loc[idx, 'text'][:200]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cross-Validation\n",
    "\n",
    "Perform 5-fold cross-validation on the training data to get a more realistic performance estimate and check for overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results (5-fold):\n",
      "==================================================\n",
      "Accuracy:  0.9343 ¬± 0.0022\n",
      "Precision: 0.9232 ¬± 0.0045\n",
      "Recall:    0.9476 ¬± 0.0012\n",
      "F1-Score:  0.9352 ¬± 0.0020\n",
      "\n",
      "==================================================\n",
      "Comparison with Test Set Performance:\n",
      "==================================================\n",
      "Metric       CV Score (mean ¬± std)     Test Score      Difference     \n",
      "-------------------------------------------------------------------\n",
      "Accuracy     0.9343 ¬± 0.0022           0.9356          0.0014\n",
      "Precision    0.9232 ¬± 0.0045           0.9251          0.0019\n",
      "Recall       0.9476 ¬± 0.0012           0.9483          0.0006\n",
      "F1-Score     0.9352 ¬± 0.0020           0.9365          0.0013\n",
      "\n",
      "==================================================\n",
      "Interpretation:\n",
      "==================================================\n",
      "‚úì Test and CV scores are similar. Model appears to generalize well.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=1000,\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 1),\n",
    "        min_df=2,\n",
    "        max_df=0.95\n",
    "    )),\n",
    "    ('classifier', LogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        C=0.01\n",
    "    ))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_accuracy = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "cv_precision = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='precision', n_jobs=-1)\n",
    "cv_recall = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='recall', n_jobs=-1)\n",
    "cv_f1 = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='f1', n_jobs=-1)\n",
    "\n",
    "print(\"Cross-Validation Results (5-fold):\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy:  {cv_accuracy.mean():.4f} ¬± {cv_accuracy.std():.4f}\")\n",
    "print(f\"Precision: {cv_precision.mean():.4f} ¬± {cv_precision.std():.4f}\")\n",
    "print(f\"Recall:    {cv_recall.mean():.4f} ¬± {cv_recall.std():.4f}\")\n",
    "print(f\"F1-Score:  {cv_f1.mean():.4f} ¬± {cv_f1.std():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Comparison with Test Set Performance:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Metric':<12} {'CV Score (mean ¬± std)':<25} {'Test Score':<15} {'Difference':<15}\")\n",
    "print(\"-\" * 67)\n",
    "\n",
    "cv_acc_str = f\"{cv_accuracy.mean():.4f} ¬± {cv_accuracy.std():.4f}\"\n",
    "cv_prec_str = f\"{cv_precision.mean():.4f} ¬± {cv_precision.std():.4f}\"\n",
    "cv_rec_str = f\"{cv_recall.mean():.4f} ¬± {cv_recall.std():.4f}\"\n",
    "cv_f1_str = f\"{cv_f1.mean():.4f} ¬± {cv_f1.std():.4f}\"\n",
    "\n",
    "test_acc_str = f\"{accuracy:.4f}\"\n",
    "test_prec_str = f\"{precision:.4f}\"\n",
    "test_rec_str = f\"{recall:.4f}\"\n",
    "test_f1_str = f\"{f1:.4f}\"\n",
    "\n",
    "print(f\"{'Accuracy':<12} {cv_acc_str:<25} {test_acc_str:<15} {(accuracy - cv_accuracy.mean()):.4f}\")\n",
    "print(f\"{'Precision':<12} {cv_prec_str:<25} {test_prec_str:<15} {(precision - cv_precision.mean()):.4f}\")\n",
    "print(f\"{'Recall':<12} {cv_rec_str:<25} {test_rec_str:<15} {(recall - cv_recall.mean()):.4f}\")\n",
    "print(f\"{'F1-Score':<12} {cv_f1_str:<25} {test_f1_str:<15} {(f1 - cv_f1.mean()):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Interpretation:\")\n",
    "print(\"=\" * 50)\n",
    "if accuracy - cv_accuracy.mean() > 0.05:\n",
    "    print(\"‚ö†Ô∏è  WARNING: Test accuracy is significantly higher than CV accuracy.\")\n",
    "    print(\"   This suggests potential overfitting. The model may not generalize well to new data.\")\n",
    "elif accuracy - cv_accuracy.mean() > 0.02:\n",
    "    print(\"‚ö†Ô∏è  CAUTION: Test accuracy is slightly higher than CV accuracy.\")\n",
    "    print(\"   Some overfitting may be present.\")\n",
    "else:\n",
    "    print(\"‚úì Test and CV scores are similar. Model appears to generalize well.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results\n",
    "\n",
    "Save model performance metrics and summary to a markdown file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../outputs/simple_classification_results.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs('../outputs', exist_ok=True)\n",
    "\n",
    "results_content = f\"\"\"# Simple Fake News Classification Results\n",
    "\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Dataset Information\n",
    "- Total articles: {len(df):,}\n",
    "- Training samples: {len(X_train):,}\n",
    "- Test samples: {len(X_test):,}\n",
    "\n",
    "## Preprocessing\n",
    "- Removed news sources: (reuters), (reuter), (ap), (afp) - case insensitive\n",
    "- Removed standalone \"reuters\" and \"reuter\" as whole words - case insensitive\n",
    "- Removed caps+colon patterns at start of text (e.g., \"UNBELIEVABLE:\")\n",
    "\n",
    "## Model Configuration\n",
    "- Algorithm: Logistic Regression\n",
    "- TF-IDF Features: {X_train_tfidf.shape[1]:,}\n",
    "- N-grams: (1, 1) - unigrams only\n",
    "- Max features: 1000\n",
    "- Regularization (C): 0.01 (strong regularization to reduce overfitting)\n",
    "\n",
    "## Model Performance (Test Set)\n",
    "- **Accuracy**: {accuracy:.4f} ({accuracy*100:.2f}%)\n",
    "- **Precision**: {precision:.4f}\n",
    "- **Recall**: {recall:.4f}\n",
    "- **F1-Score**: {f1:.4f}\n",
    "\n",
    "## Cross-Validation Performance (5-fold)\n",
    "- **CV Accuracy**: {cv_accuracy.mean():.4f} ¬± {cv_accuracy.std():.4f}\n",
    "- **CV Precision**: {cv_precision.mean():.4f} ¬± {cv_precision.std():.4f}\n",
    "- **CV Recall**: {cv_recall.mean():.4f} ¬± {cv_recall.std():.4f}\n",
    "- **CV F1-Score**: {cv_f1.mean():.4f} ¬± {cv_f1.std():.4f}\n",
    "\n",
    "## Overfitting Analysis\n",
    "- Test vs CV Accuracy Difference: {(accuracy - cv_accuracy.mean()):.4f}\n",
    "- {'‚ö†Ô∏è WARNING: Significant overfitting detected' if accuracy - cv_accuracy.mean() > 0.05 else '‚ö†Ô∏è CAUTION: Some overfitting may be present' if accuracy - cv_accuracy.mean() > 0.02 else '‚úì Model generalizes well'}\n",
    "\n",
    "## Summary\n",
    "The Logistic Regression classifier achieved {accuracy*100:.2f}% accuracy on the test set, with a balanced F1-score of {f1:.4f}. Cross-validation shows {cv_accuracy.mean()*100:.2f}% accuracy, indicating {'potential overfitting' if accuracy - cv_accuracy.mean() > 0.02 else 'good generalization'}. The model uses enhanced preprocessing to remove news sources and caps+colon patterns (common in fake news), followed by standard NLP preprocessing (stemming, stopword removal).\n",
    "\"\"\"\n",
    "\n",
    "with open('../outputs/simple_classification_results.md', 'w') as f:\n",
    "    f.write(results_content)\n",
    "\n",
    "print(\"Results saved to ../outputs/simple_classification_results.md\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Model\n",
    "\n",
    "Export the trained model and TF-IDF vectorizer for GCP deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model saved to ../deployable/exported_model.pkl\n",
      "‚úì TF-IDF vectorizer saved to ../deployable/tfidf_vectorizer.pkl\n",
      "‚úì Combined pipeline saved to ../deployable/model_pipeline.pkl\n",
      "\n",
      "üì¶ Model export completed successfully!\n",
      "   Files ready for GCP deployment:\n",
      "   - ../deployable/exported_model.pkl\n",
      "   - ../deployable/tfidf_vectorizer.pkl\n",
      "   - ../deployable/model_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "os.makedirs('../deployable', exist_ok=True)\n",
    "\n",
    "model_path = '../deployable/exported_model.pkl'\n",
    "vectorizer_path = '../deployable/tfidf_vectorizer.pkl'\n",
    "pipeline_path = '../deployable/model_pipeline.pkl'\n",
    "\n",
    "joblib.dump(lr_model, model_path)\n",
    "print(f\"‚úì Model saved to {model_path}\")\n",
    "\n",
    "joblib.dump(tfidf, vectorizer_path)\n",
    "print(f\"‚úì TF-IDF vectorizer saved to {vectorizer_path}\")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('classifier', lr_model)\n",
    "])\n",
    "joblib.dump(pipeline, pipeline_path)\n",
    "print(f\"‚úì Combined pipeline saved to {pipeline_path}\")\n",
    "\n",
    "print(f\"\\nüì¶ Model export completed successfully!\")\n",
    "print(f\"   Files ready for GCP deployment:\")\n",
    "print(f\"   - {model_path}\")\n",
    "print(f\"   - {vectorizer_path}\")\n",
    "print(f\"   - {pipeline_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
