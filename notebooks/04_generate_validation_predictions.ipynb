{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate Predictions for Validation Data\n",
        "\n",
        "This notebook loads the trained Logistic Regression model and generates predictions for validation_data.csv, replacing the label column (currently 2) with model predictions (0=fake, 1=real).\n",
        "\n",
        "## Overview\n",
        "- **Goal**: Generate predictions for validation data using the trained model\n",
        "- **Model**: Logistic Regression (from notebook 03)\n",
        "- **Input**: `dataset/validation_data.csv` (with label=2)\n",
        "- **Output**: Updated validation_data.csv with predictions (0 or 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import joblib\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    print(\"Libraries imported successfully!\")\n",
        "except:\n",
        "    print(\"NLTK data download failed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Trained Model and Vectorizer\n",
        "\n",
        "Load the trained Logistic Regression model and TF-IDF vectorizer from the deployable directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Pipeline loaded from ../deployable/model_pipeline.pkl\n",
            "  Using combined pipeline for predictions\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "model_path = '../deployable/exported_model.pkl'\n",
        "vectorizer_path = '../deployable/tfidf_vectorizer.pkl'\n",
        "pipeline_path = '../deployable/model_pipeline.pkl'\n",
        "\n",
        "try:\n",
        "    # Try loading pipeline first (easiest option)\n",
        "    if os.path.exists(pipeline_path):\n",
        "        pipeline = joblib.load(pipeline_path)\n",
        "        model = None\n",
        "        vectorizer = None\n",
        "        print(f\"✓ Pipeline loaded from {pipeline_path}\")\n",
        "        print(\"  Using combined pipeline for predictions\")\n",
        "    else:\n",
        "        # Load model and vectorizer separately\n",
        "        model = joblib.load(model_path)\n",
        "        vectorizer = joblib.load(vectorizer_path)\n",
        "        pipeline = None\n",
        "        print(f\"✓ Model loaded from {model_path}\")\n",
        "        print(f\"✓ Vectorizer loaded from {vectorizer_path}\")\n",
        "        print(\"  Using separate model and vectorizer for predictions\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"❌ Error: Model files not found!\")\n",
        "    print(f\"   Please run notebook 03_simple_classification.ipynb first to export the model.\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading model: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Validation Data\n",
        "\n",
        "Load the validation dataset that needs predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation data shape: (4956, 5)\n",
            "Columns: ['label', 'title', 'text', 'subject', 'date']\n",
            "\n",
            "Label distribution:\n",
            "label\n",
            "2    4956\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample articles:\n",
            "\n",
            "  Article 1:\n",
            "    Title: UK's May 'receiving regular updates' on London tube station incident: PM's office...\n",
            "    Text length: 389 characters\n",
            "    Current label: 2\n",
            "\n",
            "  Article 2:\n",
            "    Title: UK transport police leading investigation of London incident, counter-terrorism police aware...\n",
            "    Text length: 499 characters\n",
            "    Current label: 2\n",
            "\n",
            "  Article 3:\n",
            "    Title: Pacific nations crack down on North Korean ships as Fiji probes more than 20 vessels...\n",
            "    Text length: 2685 characters\n",
            "    Current label: 2\n"
          ]
        }
      ],
      "source": [
        "validation_df = pd.read_csv('../dataset/validation_data.csv')\n",
        "\n",
        "print(f\"Validation data shape: {validation_df.shape}\")\n",
        "print(f\"Columns: {validation_df.columns.tolist()}\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "print(validation_df['label'].value_counts().sort_index())\n",
        "\n",
        "print(f\"\\nSample articles:\")\n",
        "for i in range(min(3, len(validation_df))):\n",
        "    print(f\"\\n  Article {i+1}:\")\n",
        "    print(f\"    Title: {validation_df.iloc[i]['title'][:100]}...\")\n",
        "    print(f\"    Text length: {len(validation_df.iloc[i]['text'])} characters\")\n",
        "    print(f\"    Current label: {validation_df.iloc[i]['label']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Apply Preprocessing\n",
        "\n",
        "Apply the same preprocessing function used during training to match the model's expected input format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing validation data...\n",
            "⚠️  Removing 2 articles with empty processed text\n",
            "✓ Preprocessing completed: 4954 articles ready for prediction\n",
            "  Average processed text length: 299.8 words\n"
          ]
        }
      ],
      "source": [
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def standard_preprocess(text):\n",
        "    \"\"\"Preprocess text to match training preprocessing.\"\"\"\n",
        "    if pd.isna(text) or text == \"\":\n",
        "        return \"\"\n",
        "    \n",
        "    text_str = str(text)\n",
        "    \n",
        "    # Remove news sources (case-insensitive)\n",
        "    text_str = re.sub(r'\\(reuters\\)|\\(reuter\\)|\\(ap\\)|\\(afp\\)', '', text_str, flags=re.IGNORECASE)\n",
        "    text_str = re.sub(r'\\breuters\\b', '', text_str, flags=re.IGNORECASE)\n",
        "    text_str = re.sub(r'\\breuter\\b', '', text_str, flags=re.IGNORECASE)\n",
        "    \n",
        "    # Remove caps+colon patterns at start\n",
        "    text_str = re.sub(r'^[A-Z]{5,}:\\s*', '', text_str)\n",
        "    \n",
        "    text_str = text_str.lower()\n",
        "    text_str = re.sub(r'http\\S+|www\\S+|https\\S+', '', text_str)\n",
        "    text_str = re.sub(r'\\S+@\\S+', '', text_str)\n",
        "    text_str = re.sub(r'\\s+', ' ', text_str)\n",
        "    \n",
        "    try:\n",
        "        tokens = word_tokenize(text_str)\n",
        "    except:\n",
        "        tokens = text_str.split()\n",
        "    \n",
        "    tokens = [token for token in tokens if token.lower() not in stop_words]\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "    \n",
        "    return ' '.join(tokens)\n",
        "\n",
        "print(\"Preprocessing validation data...\")\n",
        "validation_df['title_processed'] = validation_df['title'].apply(standard_preprocess)\n",
        "validation_df['text_processed'] = validation_df['text'].apply(standard_preprocess)\n",
        "validation_df['combined_text'] = validation_df['title_processed'] + ' ' + validation_df['text_processed']\n",
        "\n",
        "# Remove articles with empty processed text\n",
        "empty_text = validation_df['combined_text'].str.strip() == ''\n",
        "empty_count = empty_text.sum()\n",
        "if empty_count > 0:\n",
        "    print(f\"⚠️  Removing {empty_count} articles with empty processed text\")\n",
        "    validation_df = validation_df[~empty_text].reset_index(drop=True)\n",
        "\n",
        "print(f\"✓ Preprocessing completed: {len(validation_df)} articles ready for prediction\")\n",
        "print(f\"  Average processed text length: {validation_df['combined_text'].str.split().str.len().mean():.1f} words\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Generate Predictions\n",
        "\n",
        "Use the trained model to generate predictions for all validation articles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating predictions...\n",
            "✓ Predictions generated for 4954 articles\n",
            "\n",
            "Prediction distribution:\n",
            "label\n",
            "0    2987\n",
            "1    1967\n",
            "Name: count, dtype: int64\n",
            "\n",
            "  Fake (0): 2,987 articles (60.3%)\n",
            "  Real (1): 1,967 articles (39.7%)\n",
            "\n",
            "Sample predictions:\n",
            "  1. Real (confidence: 0.668) | 'UK's May 'receiving regular updates' on London tube station incident: PM's offic...'\n",
            "  2. Real (confidence: 0.580) | 'UK transport police leading investigation of London incident, counter-terrorism ...'\n",
            "  3. Real (confidence: 0.762) | 'Pacific nations crack down on North Korean ships as Fiji probes more than 20 ves...'\n",
            "  4. Real (confidence: 0.778) | 'Three suspected al Qaeda militants killed in Yemen drone strike...'\n",
            "  5. Real (confidence: 0.815) | 'Chinese academics prod Beijing to consider North Korea contingencies...'\n"
          ]
        }
      ],
      "source": [
        "print(\"Generating predictions...\")\n",
        "\n",
        "if pipeline:\n",
        "    # Use pipeline (includes vectorization + prediction)\n",
        "    predictions = pipeline.predict(validation_df['combined_text'])\n",
        "    probabilities = pipeline.predict_proba(validation_df['combined_text'])\n",
        "else:\n",
        "    # Use separate model and vectorizer\n",
        "    text_vectorized = vectorizer.transform(validation_df['combined_text'])\n",
        "    predictions = model.predict(text_vectorized)\n",
        "    probabilities = model.predict_proba(text_vectorized)\n",
        "\n",
        "# Replace label column with predictions\n",
        "validation_df['label'] = predictions\n",
        "\n",
        "print(f\"✓ Predictions generated for {len(validation_df)} articles\")\n",
        "print(f\"\\nPrediction distribution:\")\n",
        "print(validation_df['label'].value_counts().sort_index())\n",
        "print(f\"\\n  Fake (0): {(validation_df['label'] == 0).sum():,} articles ({(validation_df['label'] == 0).sum()/len(validation_df)*100:.1f}%)\")\n",
        "print(f\"  Real (1): {(validation_df['label'] == 1).sum():,} articles ({(validation_df['label'] == 1).sum()/len(validation_df)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nSample predictions:\")\n",
        "for i in range(min(5, len(validation_df))):\n",
        "    pred = int(predictions[i])\n",
        "    conf = probabilities[i, pred]\n",
        "    pred_name = 'Fake' if pred == 0 else 'Real'\n",
        "    title = validation_df.iloc[i]['title'][:80]\n",
        "    print(f\"  {i+1}. {pred_name} (confidence: {conf:.3f}) | '{title}...'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save Updated Validation Data\n",
        "\n",
        "Save the validation data with predictions replacing the original label column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output format verification:\n",
            "  Columns: ['label', 'title', 'text', 'subject', 'date']\n",
            "  Shape: (4954, 5)\n",
            "  Label range: 0 to 1\n",
            "  Label types: [np.int64(0), np.int64(1)]\n",
            "\n",
            "✓ Updated validation_data.csv saved to ../dataset/validation_data.csv\n",
            "  Total articles: 4,954\n",
            "  Fake predictions: 2,987\n",
            "  Real predictions: 1,967\n",
            "✓ Backup saved to ../dataset/validation_data_backup_20251115_130214.csv\n",
            "\n",
            "✅ Validation data predictions completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Prepare output dataframe with original columns (excluding processed columns)\n",
        "output_df = validation_df[['label', 'title', 'text', 'subject', 'date']].copy()\n",
        "\n",
        "# Verify the output format\n",
        "print(\"Output format verification:\")\n",
        "print(f\"  Columns: {output_df.columns.tolist()}\")\n",
        "print(f\"  Shape: {output_df.shape}\")\n",
        "print(f\"  Label range: {output_df['label'].min()} to {output_df['label'].max()}\")\n",
        "print(f\"  Label types: {sorted(output_df['label'].unique())}\")\n",
        "\n",
        "# Save to validation_data.csv (overwriting original)\n",
        "output_path = '../dataset/validation_data.csv'\n",
        "output_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"\\n✓ Updated validation_data.csv saved to {output_path}\")\n",
        "print(f\"  Total articles: {len(output_df):,}\")\n",
        "print(f\"  Fake predictions: {(output_df['label'] == 0).sum():,}\")\n",
        "print(f\"  Real predictions: {(output_df['label'] == 1).sum():,}\")\n",
        "\n",
        "# Also save a backup copy with timestamp\n",
        "from datetime import datetime\n",
        "backup_path = f'../dataset/validation_data_backup_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
        "output_df.to_csv(backup_path, index=False)\n",
        "print(f\"✓ Backup saved to {backup_path}\")\n",
        "\n",
        "print(f\"\\n✅ Validation data predictions completed successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
