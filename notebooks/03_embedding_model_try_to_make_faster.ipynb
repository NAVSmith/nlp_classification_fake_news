{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Fake vs Real News Classification - Embedding-based Model\n",
    "\n",
    "This notebook explores an alternative approach to the TF-IDF model by using word embeddings to represent the text data.\n",
    "\n",
    "## Project Goal\n",
    "Build a classifier to distinguish between real (1) and fake (0) news articles using word embeddings.\n",
    "\n",
    "## Workflow\n",
    "1. Load preprocessed training and testing data.\n",
    "2. Use a pre-trained language model from `spaCy` to generate document embeddings.\n",
    "3. Train multiple classification models on the embeddings.\n",
    "4. Evaluate and compare model performance against the TF-IDF models.\n",
    "5. Select the best performing model and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries and spaCy model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import joblib\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB # Using GaussianNB for continuous features\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, classification_report)\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "print(\"Libraries and spaCy model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d23c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data...\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed training and testing data\n",
    "print(\"Loading preprocessed data...\")\n",
    "\n",
    "train_data = pd.read_csv('../data/processed/train.csv')\n",
    "test_data = pd.read_csv('../data/processed/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "346e51f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_processed",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title_length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title_word_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_word_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c4bd9af7-0646-491a-9818-19cae5541c84",
       "rows": [
        [
         "0",
         "hear presid trump doubl condemn evil kkk white supremacist neonazi video transcript presid trump condemn hate group today ye seem left hear presid first time around need special speech still find someth complain allow trump good guy fit narr matter beauti speech today democrat continu rhetor trump last thing want unit america presid thank washington today meet econom team trade polici major tax cut reform renegoti trade deal make good american worker timeour economi strong stock market continu hit record high unemploy year low busi optimist ever compani move back unit state bring mani thousand job alreadi creat one million job sinc took officew discuss econom issu greater detail later afternoon base event took place weekend charlottesvil virginia would like provid nation updat ongo feder respons horrif attack violenc wit everyonei met fbi director christoph wray attorney gener jeff session depart justic open civil right investig deadli car attack kill one innoc american wound other anyon act crimin weekend racist violenc held fulli account justic delivereda said saturday condemn strongest possibl term egregi display hatr bigotri violenc place americaand said mani time matter color skin live law salut great flag made almighti god must love show affect unit togeth condemn hatr bigotri violenc must rediscov bond love loyalti bring togeth americansrac evil caus violenc name crimin thug includ kkk neonazi white supremacist hate group repugn everyth hold dear americansw nation found truth creat equal equal eye creator equal law equal constitut spread violenc name bigotri strike core americatwo day ago young american woman heather heyer tragic kill death fill grief send famili thought prayer lovew also mourn two virginia state trooper die servic commun commonwealth countri trooper jay cullen burk bate exemplifi best america heart famili friend everi member american law enforcementthes three fallen american embodi good decenc nation time america alway shown true charact respond hate love divis uniti violenc unwav resolv justicea candid promis restor law order countri feder law enforc agenc follow pledg spare resourc fight everi american child grow free violenc fear defend protect sacr right american work togeth everi citizen bless land free follow dream heart express love joy soulsthank god bless god bless america thank much",
         "0",
         "125",
         "3940",
         "18",
         "677"
        ],
        [
         "1",
         "wow christian author give unexpect brilliant answer muslim law student claim she worri portray islam muslim bad brigitt gabriel born marjeyoun district lebanon maronit christian coupl first child twenti year marriag recal lebanes civil war islam milit launch assault lebanes militari base near famili hous destroy home gabriel ten year old time injur shrapnel attack say parent forc live underground remain byfoot bomb shelter seven year small kerosen heater sanitari system electr run water littl food say crawl roadsid ditch spring water evad muslim snipersaccord gabriel one point spring bomb explos caus parent becom trap shelter two daysthey eventu rescu three christian militia fightersbrigitt gabriel american citizen author founder act conserv lectur gabriel attend benghazi account coalit forum suppos benghazi govern held respons action led death four american thing took dramat turn saba ahm muslim law student america univers stood defend major follow islam told panel portray islam muslim bad billion follow islam million plu muslim american countri see repres gabriel answer question histor perspect knock park gave answer ahm turn islam activist also activ democrat polit time event took placewatch",
         "0",
         "157",
         "1874",
         "25",
         "324"
        ],
        [
         "2",
         "obama black live matter terrorist join peopl live countri illeg union anarchist muslim threaten america massiv riot come hell high water occupi movement go voic heard commun organ chief occupi white hous pretti much everi hateamerica victim group take part act civil disobedi plan group know critic import take action alli white hous prepar whatev take ensur republican unabl unravel radic progress unconstitut act barack hussein obamafriday night chicago site donald trump ralli awaken america like continu kowtow radic left violent intimid tactic shut constitut protect speech protest movement pure anarchyaft eight year presid obama totalitarian enemi freedom know constitut republ rope go throatgo video preview organ resist took place outsid trump ralli chicagobreitbart littl fanfar almost news media attent radic group involv shut donald trump chicago ralli last week plot mass civil disobedi movement begin next monththey intend march across east coast order spark fire transform polit climat america oper call democraci spring threaten drama washington largest civil disobedi action centuri radic believ result arrest thousand activist demand congress listen peopl take immedi action save democraci leav send thousand jail websit democraci spring declar channel rhetor occupi movementth group back numer organ includ georg sorosfund group moveonorg institut polici studi demosanoth group endors democraci spring democrat socialist america dsa dsa chicago branch drove protest last weekend nix chicago trump event report exposedth aflcio nation largest labor feder announc press releas earlier month behind democraci spring perhap indic signific mobilizationnext month democraci spring chao set begin meetup april liberti bell philadelphiafrom trump ralli riot organ websitequoteboxcenterstand immigr muslim peopl color shut white supremacyspread word organ everyon get import protest everywher trump goe racist mob must shut peoplew must take trump campaign serious racist reactionari presidenti campaign donald trump brought mani thousand peopl ralli across countri spark danger mass movement white supremaci corethi type movement must met largest resist peopl possibl anywher rais putrid head need right thousand peopl chicago descend uic pavilion help spark unit mass movement racism islamophobia attack immigrantsquoteboxcenterthes radic anarchist riotstart come underground readi seiz prize presidenti elect process german republ stop liberti repres system way lifesom right conserv media tri find way appeas riotstart walk eggshel hope avoid truth situat palat neutral safe space tone rhetor help negoti way conflictthes rebellion brought anarchist show intent creat chao live breath violenc disord placat except silenc disagre presenc threat order liberti unit statesthi totalitarian movement riotstart made patchwork quilt cophat crimin anarchist gener univers student organ labor along way ralli pick encourag peopl get involv see univers student juvenil crimin use tool profession organ stealth natur rebellion wolf sheep cloth dupe peopl along wayw need stop blame victim muster courag stand danger movement noth individu candid polici posit rhetor everyth trump support right assembl peaceablyth lawabid men women show ralli want particip includ candid civil right afford constitut violat start expect back eitherwhat expect frankli american expect exercis constitut right peopl tri intimid shut give event noth compar happen republican convent cleveland design intimidateth presid unit state one respons creat divis america stoke racial discord class warfar gender warfar last eight yearsif anarchist truli care violenc hate would south side chicago friday night protest current state street violenc hour period last week peopl shot peopl murder first two month year peopl shot leav nearli deadsuggest donald trump tone farcic misidentifi goal riotstart one blame except sens cherish thing anarchist detest freedom riotstart placat make fear give first amend rightslawabid american must cannot back freedomsquash goon time understand enemi want achiev chao fear ralli around fundament truth constitutionour order liberti stake point founder said enough go war stand fight neutral appeas amount endors selfflagel languag rhetor cede left fals narr safe space either fight go live totalitarian regimean ope democrat sheriff david clark",
         "0",
         "160",
         "7174",
         "24",
         "1177"
        ],
        [
         "3",
         "brexit deal risk chao drug suppli report warn london crash european union without deal would caus major problem britain health servic risk chaotic disrupt medicin suppli accord report tuesday nuffield trust independ health chariti also warn brexit without deal futur relat would lead worsen staff shortag nation health servic nh could creat particular problem healthcar northern ireland treatment program rare seriou diseas design work across entir island ireland scenario leav without deal would caus extens problem nh would risk chaotic disrupt suppli medic product rise price would push hospit deeper deficit report state mani differ part law institut play import role enabl care deliv standard see today suddenli end replac would seriou damag alreadi strain british nh warn chime concern pharmaceut compani alreadi draw plan protect suppli chain stringent medicin regul mean manufactur face multipl brexit uncertainti potenti need retest drug ship across border transfer product licenc differ jurisdict",
         "1",
         "60",
         "1434",
         "11",
         "224"
        ],
        [
         "4",
         "insan iowa republican liter want let toddler carri gun iowa republican way toddler abl carri gun make state scariest nationth iowa hous liter pass seri gun bill tuesday includ hous file allow becom law would let kid age carri gun could possibl wrongaccord iowa public radiodemocrat kirsten runningmarquardt ask kind gun would fit hand two three year old got bill right front runningmarquardt said valid question miss whole point bill repli johnston republican jake highfil think one best bill done second amend right current iowa law prohibit children age possess handgun ammunit reason measur consid kid injur kill everi year gun onefifth accidentsand even count accident shoot adult children handl gunsdemocrat rep mari mascher point nineyear old girl parent instructor supervis arizona gun rang accident shot kill instructor handl gun unfortun instructor parent made wrong decis someon die mascher said everi three hour countri child die gun violenc exampl show kid allow access gunsin januari fiveyearold boy kill littl brother gun found lie around housein august year fouryearold boy shot kill mother find gun car thought toythen yearold boy kill littl girl let pet puppyor threeyearold boy live knowledg accident shot kill mom find load gun couchand stori fiveyearold boy shot kill littl sister rifl given birthday parent believ child safeti featur would enough keep gun accident firedth bottom line toddler clue gun lack physic mental capac handl firearm respons matter nra say clearli mani parent stupid come mix gun kid result horrifi heartbreak sure dead kid parent bill becom lawth bill head democratcontrol iowa senat logic reason hope prevailfeatur imag via freakout nation",
         "0",
         "66",
         "2836",
         "10",
         "496"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>label</th>\n",
       "      <th>title_length</th>\n",
       "      <th>text_length</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>text_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hear presid trump doubl condemn evil kkk white...</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>3940</td>\n",
       "      <td>18</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wow christian author give unexpect brilliant a...</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>1874</td>\n",
       "      <td>25</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obama black live matter terrorist join peopl l...</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>7174</td>\n",
       "      <td>24</td>\n",
       "      <td>1177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brexit deal risk chao drug suppli report warn ...</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1434</td>\n",
       "      <td>11</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insan iowa republican liter want let toddler c...</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>2836</td>\n",
       "      <td>10</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text_processed  label  title_length  \\\n",
       "0  hear presid trump doubl condemn evil kkk white...      0           125   \n",
       "1  wow christian author give unexpect brilliant a...      0           157   \n",
       "2  obama black live matter terrorist join peopl l...      0           160   \n",
       "3  brexit deal risk chao drug suppli report warn ...      1            60   \n",
       "4  insan iowa republican liter want let toddler c...      0            66   \n",
       "\n",
       "   text_length  title_word_count  text_word_count  \n",
       "0         3940                18              677  \n",
       "1         1874                25              324  \n",
       "2         7174                24             1177  \n",
       "3         1434                11              224  \n",
       "4         2836                10              496  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (31948, 6)\n",
      "Testing data shape: (7987, 6)\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Testing data shape: {test_data.shape}\")\n",
    "\n",
    "\n",
    "X_train_text = train_data['text_processed']\n",
    "y_train = train_data['label']\n",
    "X_test_text = test_data['text_processed']\n",
    "y_test = test_data['label']\n",
    "\n",
    "print(f\"Data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecc7b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document embeddings...\n",
      "66748\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-13:\n",
      "Process Process-12:\n",
      "Process Process-11:\n",
      "Process Process-10:\n",
      "Process Process-14:\n",
      "Process Process-9:\n",
      "Process Process-15:\n",
      "Process Process-16:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/smithn5/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/spacy/language.py\", line 2419, in _apply_pipes\n",
      "    sender.send(data)\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 421, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 384, in _send\n",
      "    n = write(self._handle, buf)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/smithn5/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/spacy/language.py\", line 2419, in _apply_pipes\n",
      "    sender.send(data)\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 421, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 384, in _send\n",
      "    n = write(self._handle, buf)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/smithn5/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/spacy/language.py\", line 2419, in _apply_pipes\n",
      "    sender.send(data)\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 421, in _send_bytes\n",
      "    self._send(buf)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 384, in _send\n",
      "    n = write(self._handle, buf)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/smithn5/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/spacy/language.py\", line 2394, in _apply_pipes\n",
      "    texts_with_ctx = receiver.get()\n",
      "                     ^^^^^^^^^^^^^^\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/smithn5/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/spacy/language.py\", line 2419, in _apply_pipes\n",
      "    sender.send(data)\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 421, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 384, in _send\n",
      "    n = write(self._handle, buf)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/smithn5/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/spacy/language.py\", line 2419, in _apply_pipes\n",
      "    sender.send(data)\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 421, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 384, in _send\n",
      "    n = write(self._handle, buf)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/smithn5/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/spacy/language.py\", line 2394, in _apply_pipes\n",
      "    texts_with_ctx = receiver.get()\n",
      "                     ^^^^^^^^^^^^^^\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/smithn5/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/spacy/language.py\", line 2419, in _apply_pipes\n",
      "    sender.send(data)\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 421, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/Users/smithn5/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/connection.py\", line 384, in _send\n",
      "    n = write(self._handle, buf)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "/Users/smithn5/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/spacy/language.py:1736: UserWarning: [W127] Not all `Language.pipe` worker processes completed successfully\n",
      "  warnings.warn(Warnings.W127)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m texts = X_train_text.tolist()\n\u001b[32m     27\u001b[39m X_train = generate_embeddings(X_train_text)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m X_test = \u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbeddings generated successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mgenerate_embeddings\u001b[39m\u001b[34m(text_series)\u001b[39m\n\u001b[32m     18\u001b[39m embs = []\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m nlp.pipe(texts, n_process=-\u001b[32m1\u001b[39m, batch_size=\u001b[32m200\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     emb = \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     embs.append(emb)\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(embs), end=\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mget_embedding\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_embedding\u001b[39m(text):\n\u001b[32m      5\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Generate a document embedding by averaging word vectors.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     doc = \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# We filter out stop words and punctuation, and only use tokens with vectors.\u001b[39;00m\n\u001b[32m      8\u001b[39m     vectors = [token.vector \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc \u001b[38;5;28;01mif\u001b[39;00m token.has_vector \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token.is_stop \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token.is_punct]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/spacy/language.py:1053\u001b[39m, in \u001b[36mLanguage.__call__\u001b[39m\u001b[34m(self, text, disable, component_cfg)\u001b[39m\n\u001b[32m   1051\u001b[39m     error_handler = proc.get_error_handler()\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m     doc = \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcomponent_cfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1055\u001b[39m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[32m   1056\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors.E109.format(name=name)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[39m, in \u001b[36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/spacy/pipeline/transition_parser.pyx:264\u001b[39m, in \u001b[36mspacy.pipeline.transition_parser.Parser.predict\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/spacy/pipeline/transition_parser.pyx:285\u001b[39m, in \u001b[36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/model.py:334\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) -> OutT:\n\u001b[32m    331\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[33;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[32m    333\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/spacy/ml/tb_framework.py:33\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(model, X, is_train):\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     step_model = \u001b[43mParserStepModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43munseen_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43munseen_classes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_upper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhas_upper\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m step_model, step_model.finish_steps\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/spacy/ml/parser_model.pyx:250\u001b[39m, in \u001b[36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/layers/chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/layers/chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/layers/with_array.py:42\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, Xseq, is_train)\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model.layers[\u001b[32m0\u001b[39m](Xseq, is_train)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], \u001b[43m_list_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/layers/with_array.py:77\u001b[39m, in \u001b[36m_list_forward\u001b[39m\u001b[34m(model, Xs, is_train)\u001b[39m\n\u001b[32m     75\u001b[39m lengths = NUMPY_OPS.asarray1i([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m Xs])\n\u001b[32m     76\u001b[39m Xf = layer.ops.flatten(Xs, pad=pad)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m Yf, get_dXf = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackprop\u001b[39m(dYs: ListXd) -> ListXd:\n\u001b[32m     80\u001b[39m     dYf = layer.ops.flatten(dYs, pad=pad)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/layers/chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/layers/residual.py:41\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m d_output + dX\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m Y, backprop_layer = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [X[i] + Y[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))], backprop\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/layers/chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/layers/chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "    \u001b[31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/layers/chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ironhack/nlp_classification_fake_news/.venv/lib/python3.11/site-packages/thinc/layers/maxout.py:52\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     50\u001b[39m W = model.get_param(\u001b[33m\"\u001b[39m\u001b[33mW\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m W = model.ops.reshape2f(W, nO * nP, nI)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m Y = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgemm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans2\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m Y += model.ops.reshape1f(b, nO * nP)\n\u001b[32m     54\u001b[39m Z = model.ops.reshape3f(Y, Y.shape[\u001b[32m0\u001b[39m], nO, nP)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Generate document embeddings\n",
    "print(\"Generating document embeddings...\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"Generate a document embedding by averaging word vectors.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    # We filter out stop words and punctuation, and only use tokens with vectors.\n",
    "    vectors = [token.vector for token in doc if token.has_vector and not token.is_stop and not token.is_punct]\n",
    "    if len(vectors) > 0:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        # If no vectors are found, return a zero vector of the same dimension.\n",
    "        return np.zeros(nlp.meta['vectors']['width'])\n",
    "\n",
    "# Apply the function to the text columns\n",
    "def generate_embeddings(text_series):\n",
    "    texts = text_series.tolist()\n",
    "    embs = []\n",
    "    for text in nlp.pipe(texts, n_process=-1, batch_size=200):\n",
    "        emb = get_embedding(text)\n",
    "        embs.append(emb)\n",
    "        print(len(embs), end='\\r')\n",
    "\n",
    "    return np.vstack(embs).astype(np.float32)\n",
    "# This may take a few minutes to run\n",
    "texts = X_train_text.tolist()\n",
    "X_train = generate_embeddings(X_train_text)\n",
    "X_test = generate_embeddings(X_test_text)\n",
    "print(f\"Embeddings generated successfully!\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69e99e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 4 models for training.\n"
     ]
    }
   ],
   "source": [
    "# Define machine learning models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'Gaussian Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(models)} models for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea972e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating models...\n",
      "============================================================\n",
      "\n",
      " Training Logistic Regression...\n",
      "   Training completed in 0.7 seconds\n",
      "    Accuracy:    0.9253\n",
      "    Precision:   0.9165\n",
      "    Recall:      0.9360\n",
      "    F1-Score:    0.9262\n",
      "\n",
      " Training Random Forest...\n",
      "   Training completed in 41.9 seconds\n",
      "    Accuracy:    0.9135\n",
      "    Precision:   0.9113\n",
      "    Recall:      0.9165\n",
      "    F1-Score:    0.9139\n",
      "\n",
      " Training SVM...\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "print(\"Training and evaluating models...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n Training {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fit the model on training data\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"   Training completed in {training_time:.1f} seconds\")\n",
    "    print(f\"    Accuracy:    {accuracy:.4f}\")\n",
    "    print(f\"    Precision:   {precision:.4f}\")\n",
    "    print(f\"    Recall:      {recall:.4f}\")\n",
    "    print(f\"    F1-Score:    {f1:.4f}\")\n",
    "\n",
    "print(f\"\\n Model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990afd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model comparison table\n",
    "comparison_df = pd.DataFrame(results).T.drop(columns=['model'])\n",
    "print(\" MODEL COMPARISON (Embeddings)\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Identify best model based on F1-score\n",
    "best_model_name = comparison_df['f1'].idxmax()\n",
    "best_model = results[best_model_name]['model']\n",
    "print(f\"\\n Best performing model: {best_model_name}\")\n",
    "\n",
    "# Save the best model\n",
    "os.makedirs('../outputs/model', exist_ok=True)\n",
    "model_filename = f'../outputs/model/best_embedding_model_{best_model_name.lower().replace(\" \", \"_\")}.pkl'\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\" Best model saved to: {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408eba38",
   "metadata": {},
   "source": [
    "## Results and Comparison\n",
    "\n",
    "The table above shows the performance of different classifiers trained on the document embeddings. \n",
    "\n",
    "### Comparison with TF-IDF Models\n",
    "\n",
    "Let's compare these results with the TF-IDF based models from the previous notebook.\n",
    "\n",
    "| Model (TF-IDF)         | Accuracy | F1-Score |\n",
    "|------------------------|----------|----------|\n",
    "| Logistic Regression    | 0.9850   | 0.9850   |\n",
    "| Random Forest          | 0.9932   | 0.9933   |\n",
    "| Naive Bayes            | 0.9395   | 0.9395   |\n",
    "| Support Vector Machine | 0.9922   | 0.9923   |\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* The TF-IDF models, especially Random Forest and SVM, achieved near-perfect scores, which is suspicious given the nature of the dataset.\n",
    "* The embedding-based models have lower scores, which might be a more realistic representation of the model's performance on unseen data.\n",
    "* The difference in performance suggests that the TF-IDF approach might be overfitting to the specific vocabulary of the training data.\n",
    "* The embedding-based approach, by capturing semantic meaning, might be more robust and generalize better, even with a lower score on this specific test set.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "While the TF-IDF models show higher metrics, the embedding-based models are likely to be more reliable in a real-world scenario. The choice between the two would depend on the specific goals of the project. If the goal is to have a model that understands the content better and is less susceptible to simple keyword manipulation, the embedding-based model is a better choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
